import streamlit as st
import pandas as pd
import os
import json
import requests
import re
from deep_translator import GoogleTranslator
from datetime import datetime
import hashlib
import time
import logging
from concurrent.futures import ThreadPoolExecutor, as_completed
from rapidfuzz import fuzz
import plotly.express as px
import plotly.graph_objects as go

# --- LOGGING SETUP ---
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# --- SAYFA YAPILANDIRMASI ---
st.set_page_config(page_title="LCW Global Intelligence", layout="wide", page_icon="üßø")

# --- CSS ---
st.markdown("""
<style>
    .block-container { padding-top: 1rem !important; padding-bottom: 5rem; }
    header {visibility: hidden;}
    .stApp { background-color: #0e1117; font-family: 'Segoe UI', sans-serif; }
    h1 { color: #4da6ff; text-align: center; text-transform: uppercase; letter-spacing: 2px; text-shadow: 0 0 15px rgba(77, 166, 255, 0.6); margin-top: -20px !important; padding-bottom: 20px; }
    div[data-testid="stMetric"] { background-color: #161b22; border: 1px solid #30363d; border-radius: 12px; padding: 15px; box-shadow: 0 4px 6px rgba(0,0,0,0.5); }
    [data-testid="stMetricValue"] { color: #ffffff !important; font-size: 28px !important; font-weight: 700 !important; }
    [data-testid="stMetricLabel"] { color: #8b949e !important; font-size: 14px !important; }
    .stDataFrame { border: 1px solid #30363d; border-radius: 5px; }
    [data-testid="stSidebar"] { background-color: #0d1117; border-right: 1px solid #30363d; }
    div.stButton > button { background: linear-gradient(90deg, #1c54b2 0%, #0d3c85 100%); color: white; border: none; padding: 12px 24px; font-weight: bold; width: 100%; border-radius: 8px; }
    .stAlert { background-color: #161b22; color: #e6edf3; border: 1px solid #30363d; }
    .insight-box { background-color: #1a1f2e; border-left: 4px solid #4da6ff; padding: 15px; margin: 10px 0; border-radius: 5px; }
</style>
""", unsafe_allow_html=True)

# --- BA≈ûLIK ---
st.markdown("<h1>LCW HOME | GLOBAL INTELLIGENCE</h1>", unsafe_allow_html=True)

# --- SESSION STATE ---
if 'search_results' not in st.session_state:
    st.session_state['search_results'] = None
if 'search_history' not in st.session_state:
    st.session_state['search_history'] = []
if 'last_search_time' not in st.session_state:
    st.session_state['last_search_time'] = {}

# --- HARDCODED URL DB ---
URL_DB = {
    "Bulgaristan": { "Pepco": "https://pepco.bg/", "Sinsay": "https://www.sinsay.com/bg/bg/", "Zara Home": "https://www.zarahome.com/bg/", "H&M Home": "https://www2.hm.com/bg_bg/home.html", "Jysk": "https://jysk.bg/", "Jumbo": "https://www.jumbo.bg/", "English Home": "https://englishhome.bg/", "Primark": "https://www.primark.com/en-us" },
    "Bosna Hersek": { "Pepco": "https://pepco.ba/", "Sinsay": "https://www.sinsay.com/ba/bs/", "Zara Home": "https://www.zarahome.com/ba/", "H&M Home": "https://www.hm.com/ba", "Jysk": "https://jysk.ba/", "Jumbo": "https://www.jumbo.ba/", "English Home": "https://englishhome.ba/", "Primark": None },
    "Yunanistan": { "Pepco": "https://pepco.gr/", "Sinsay": "https://www.sinsay.com/gr/el/", "Zara Home": "https://www.zarahome.com/gr/", "H&M Home": "https://www2.hm.com/en_gr/home.html", "Jysk": "https://jysk.gr/", "Jumbo": "https://www.e-jumbo.gr/", "English Home": "https://englishhome.gr/", "Primark": None },
    "Romanya": { "Pepco": "https://pepco.ro/", "Sinsay": "https://www.sinsay.com/ro/ro/", "Zara Home": "https://www.zarahome.com/ro/", "H&M Home": "https://www2.hm.com/ro_ro/home.html", "Jysk": "https://jysk.ro/", "Jumbo": "https://www.jumbo.ro/", "English Home": "https://englishhome.ro/", "Primark": "https://www.primark.com/ro" },
    "Sƒ±rbistan": { "Pepco": "https://pepco.rs/", "Sinsay": "https://www.sinsay.com/rs/sr/", "Zara Home": "https://www.zarahome.com/rs/", "H&M Home": "https://www2.hm.com/rs_en/home.html", "Jysk": "https://jysk.rs/", "Jumbo": "https://www.jumbo.rs/", "English Home": "https://englishhome.rs/", "Primark": None },
    "Hƒ±rvatistan": { "Pepco": "https://pepco.hr/", "Sinsay": "https://www.sinsay.com/hr/hr/", "Zara Home": "https://www.zarahome.com/hr/", "H&M Home": "https://www2.hm.com/hr_hr/home.html", "Jysk": "https://jysk.hr/", "Jumbo": None, "English Home": None, "Primark": None },
    "Kazakistan": { "Pepco": None, "Sinsay": "https://www.sinsay.com/kz/ru/", "Zara Home": "https://www.zarahome.com/kz/", "H&M Home": "https://www.hm.com/kz", "Jysk": "https://jysk.kz/", "Jumbo": None, "English Home": "https://englishhome.kz/", "Primark": None },
    "Rusya": { "Pepco": None, "Sinsay": None, "Zara Home": None, "H&M Home": None, "Jysk": None, "Jumbo": None, "English Home": None, "Primark": None },
    "Ukrayna": { "Pepco": None, "Sinsay": "https://www.sinsay.com/ua/uk/", "Zara Home": "https://www.zarahome.com/ua/", "H&M Home": "https://www.hm.com/ua", "Jysk": "https://jysk.ua/", "Jumbo": None, "English Home": "https://englishhome.ua/", "Primark": None },
    "Mƒ±sƒ±r": { "Pepco": None, "Sinsay": None, "Zara Home": "https://www.zarahome.com/eg/", "H&M Home": "https://eg.hm.com/en/", "Jysk": "https://jysk.com.eg/", "Jumbo": None, "English Home": "https://englishhome.com.eg/", "Primark": None },
    "Irak": { "Pepco": None, "Sinsay": None, "Zara Home": None, "H&M Home": "https://iq.hm.com/", "Jysk": None, "Jumbo": None, "English Home": None, "Primark": None }
}

COUNTRIES_META = {
    "Bulgaristan":  {"curr": "BGN", "lang": "bg"},
    "Bosna Hersek": {"curr": "BAM", "lang": "bs"},
    "Yunanistan":   {"curr": "EUR", "lang": "el"},
    "Sƒ±rbistan":    {"curr": "RSD", "lang": "sr"},
    "Romanya":      {"curr": "RON", "lang": "ro"},
    "Hƒ±rvatistan":  {"curr": "EUR", "lang": "hr"},
    "Kazakistan":   {"curr": "KZT", "lang": "kk"},
    "Rusya":        {"curr": "RUB", "lang": "ru"},
    "Ukrayna":      {"curr": "UAH", "lang": "uk"},
    "Mƒ±sƒ±r":        {"curr": "EGP", "lang": "ar"},
    "Irak":         {"curr": "IQD", "lang": "ar"},
}

BRANDS = ["Pepco", "Sinsay", "Zara Home", "H&M Home", "Jysk", "Primark", "Jumbo", "English Home"]

# --- RATE LIMITER CLASS ---
class RateLimiter:
    def __init__(self, calls_per_minute=8):
        self.calls = []
        self.limit = calls_per_minute
    
    def wait_if_needed(self):
        now = time.time()
        self.calls = [c for c in self.calls if now - c < 60]
        
        if len(self.calls) >= self.limit:
            sleep_time = 60 - (now - self.calls[0])
            st.info(f"‚è≥ API Rate Limit - {sleep_time:.0f} saniye bekleniyor...")
            time.sleep(sleep_time)
            self.calls = []
        
        self.calls.append(now)

rate_limiter = RateLimiter(calls_per_minute=8)

# --- FONKSƒ∞YONLAR ---

@st.cache_data(ttl=3600)
def get_rates():
    """D√∂viz kurlarƒ±nƒ± √ßek ve cache'le"""
    try:
        r = requests.get("https://api.exchangerate-api.com/v4/latest/TRY", timeout=10).json()['rates']
        rates = {k: 1/v for k, v in r.items() if v > 0} 
        if "EUR" in rates: 
            rates["BAM"] = rates["EUR"] / 1.95583
        logger.info("‚úÖ Kurlar ba≈üarƒ±yla √ßekildi")
        return rates
    except Exception as e:
        logger.error(f"‚ùå Kur √ßekme hatasƒ±: {e}")
        st.error("‚ö†Ô∏è D√∂viz kurlarƒ± y√ºklenemedi. Varsayƒ±lan deƒüerler kullanƒ±lƒ±yor.")
        return {
            "USD": 34.50, "EUR": 37.20, "BGN": 19.01, "BAM": 19.01,
            "RSD": 0.32, "RON": 7.48, "KZT": 0.07, "UAH": 0.83,
            "EGP": 0.69, "IQD": 0.026
        }

def translate_logic(text, mode="to_local", target_lang="en"):
    """√áeviri fonksiyonu - hata y√∂netimi ile"""
    if not text or text.strip() == "":
        return text
    
    try:
        if mode == "to_local":
            result = GoogleTranslator(source='auto', target=target_lang).translate(text)
        elif mode == "to_english":
            result = GoogleTranslator(source='auto', target='en').translate(text)
        else:
            result = GoogleTranslator(source='auto', target='tr').translate(text)
        return result if result else text
    except Exception as e:
        logger.warning(f"‚ö†Ô∏è √áeviri hatasƒ±: {e}")
        return text

def clean_price(price_raw, currency_code="USD"):
    """Fiyat temizleme - geli≈ütirilmi≈ü regex"""
    if not price_raw: 
        return 0.0
    
    s = str(price_raw).lower()
    
    # Gereksiz kelimeleri temizle
    noise_words = ["from", "start", "to", "price", "fiyat", "only", "de la", "desde", "pre»õ"]
    for word in noise_words:
        s = s.replace(word, "")
    
    # Para birimi sembollerini temizle
    currency_symbols = ["rsd", "din", "km", "bam", "–ª–≤", "bgn", "eur", "ron", "lei", "tl", 
                       "try", "huf", "ft", "$", "‚Ç¨", "¬£", "kzt", "‚Ç∏", "uah", "‚Ç¥"]
    for symbol in currency_symbols:
        s = s.replace(symbol, "")
    
    s = s.strip()
    s = re.sub(r'[^\d.,]', '', s)
    
    if not s: 
        return 0.0
    
    try:
        # Binlik ayƒ±rƒ±cƒ± ve ondalƒ±k nokta kontrol√º
        if ',' in s and '.' in s:
            if s.rfind(',') > s.rfind('.'):
                s = s.replace('.', '').replace(',', '.')
            else:
                s = s.replace(',', '')
        elif ',' in s:
            if len(s.split(',')[-1]) == 2:
                s = s.replace(',', '.')
            else:
                s = s.replace(',', '.')
        
        return float(s)
    except Exception as e:
        logger.warning(f"‚ö†Ô∏è Fiyat parse hatasƒ±: {price_raw} -> {e}")
        return 0.0

def validate_relevance_improved(product_name_local, query_english):
    """Fuzzy matching ile geli≈ütirilmi≈ü doƒürulama"""
    try:
        prod_en = GoogleTranslator(source='auto', target='en').translate(product_name_local).lower()
        q_en = query_english.lower()
        
        # Fuzzy matching score
        similarity = fuzz.partial_ratio(q_en, prod_en)
        
        # Keyword extraction
        q_keywords = set(word for word in q_en.split() if len(word) > 2)
        p_keywords = set(word for word in prod_en.split() if len(word) > 2)
        
        # Ortak kelimeler
        common_words = q_keywords & p_keywords
        
        # Scoring sistemi
        if similarity > 75:
            return True, prod_en, "üü¢ High Match"
        elif similarity > 55 or len(common_words) >= 2:
            return True, prod_en, "üü° Partial Match"
        elif any(kw in prod_en for kw in q_keywords):
            return True, prod_en, "üü† Keyword Match"
        else:
            return False, prod_en, "üî¥ No Match"
            
    except Exception as e:
        logger.warning(f"‚ö†Ô∏è Validation hatasƒ±: {e}")
        return True, product_name_local, "‚ö™ Unknown"

def get_cache_key(brand, product, country, currency):
    """Cache key olu≈ütur"""
    key_string = f"{brand}_{product}_{country}_{currency}"
    return hashlib.md5(key_string.encode()).hexdigest()

@st.cache_data(ttl=86400, show_spinner=False)
def search_sonar_cached(brand, product_local, product_english, country, currency_code, hardcoded_url, cache_key):
    """Cached Perplexity API √ßaƒürƒ±sƒ±"""
    return search_sonar(brand, product_local, product_english, country, currency_code, hardcoded_url)

def search_sonar(brand, product_local, product_english, country, currency_code, hardcoded_url):
    """Perplexity Sonar API ile √ºr√ºn arama - Geli≈ütirilmi≈ü"""
    url = "https://api.perplexity.ai/chat/completions"
    domain = hardcoded_url.replace("https://", "").replace("http://", "").split("/")[0]

    system_msg = """You are an expert e-commerce product data scraper. 
Your task is to extract comprehensive product listings with accurate prices.
CRITICAL RULES:
1. Extract AT LEAST 15-20 products if available
2. Include different sizes, colors, and variants
3. Ensure prices are numerical and accurate
4. Include direct product URLs
5. Return ONLY valid JSON, no explanations"""
    
    user_msg = f"""
TASK: Search {hardcoded_url} for '{product_english}' (local term: '{product_local}')

REQUIREMENTS:
- Find the category page or search results
- Extract MINIMUM 15-20 products (aim for 30+ if available)
- Include various sizes (e.g., 50x90cm, 70x140cm, etc.)
- Include different colors and models
- Get accurate numerical prices in {currency_code}

OUTPUT FORMAT (JSON only):
{{
    "products": [
        {{
            "name": "Product Full Name",
            "price": "19.99",
            "size": "50x90 cm",
            "color": "Blue",
            "url": "full_product_url"
        }}
    ],
    "total_found": 25,
    "category_url": "category_page_url"
}}

IMPORTANT: Return comprehensive product list, not just top results.
"""
    
    payload = {
        "model": "sonar",
        "messages": [
            {"role": "system", "content": system_msg}, 
            {"role": "user", "content": user_msg}
        ],
        "temperature": 0.1,
        "max_tokens": 4000
    }
    
    headers = {
        "Authorization": f"Bearer {PERPLEXITY_KEY}",
        "Content-Type": "application/json"
    }
    
    try:
        rate_limiter.wait_if_needed()
        
        res = requests.post(url, json=payload, headers=headers, timeout=60)
        
        if res.status_code == 200:
            raw = res.json()['choices'][0]['message']['content']
            
            # JSON extraction
            clean = raw.replace("```json", "").replace("```", "").strip()
            start = clean.find("{")
            end = clean.rfind("}")
            
            if start != -1 and end != -1:
                clean = clean[start:end+1]
                data = json.loads(clean)
                
                # Veri kalitesi kontrol√º
                if "products" in data and len(data["products"]) > 0:
                    logger.info(f"‚úÖ {brand} - {len(data['products'])} √ºr√ºn bulundu")
                    return data
                else:
                    logger.warning(f"‚ö†Ô∏è {brand} - Bo≈ü sonu√ß")
                    return None
            else:
                logger.error(f"‚ùå {brand} - JSON parse edilemedi")
                with st.expander(f"üîç {brand} Raw Response (Debug)"):
                    st.code(raw)
                return None
        
        elif res.status_code == 429:
            st.error("‚ö†Ô∏è API Rate Limit a≈üƒ±ldƒ±. 1 dakika bekleyin.")
            time.sleep(60)
            return None
        
        else:
            logger.error(f"‚ùå API Error {res.status_code}: {res.text}")
            st.error(f"API Hatasƒ±: {res.status_code}")
            return None
            
    except requests.exceptions.Timeout:
        logger.error(f"‚è±Ô∏è Timeout: {hardcoded_url}")
        st.warning(f"‚è±Ô∏è {brand} yanƒ±t vermedi (timeout)")
        return None
        
    except json.JSONDecodeError as e:
        logger.error(f"‚ùå JSON Decode Error: {e}")
        st.error(f"ü§ñ {brand} - AI beklenmeyen format d√∂nd√º")
        return None
        
    except Exception as e:
        logger.exception(f"‚ùå Unexpected error: {e}")
        st.error(f"‚ùå {brand} - Beklenmeyen hata: {type(e).__name__}")
        return None

def generate_insights(df):
    """Otomatik analiz insights"""
    if df.empty:
        return []
    
    insights = []
    
    try:
        # En ucuz √ºr√ºn
        cheapest = df.nsmallest(1, 'TL').iloc[0]
        insights.append(f"üí∞ **En Uygun:** {cheapest['√úr√ºn T√ºrk√ße Adƒ±'][:50]}... - **{cheapest['TL']:.0f}‚Ç∫** ({cheapest['Marka']})")
        
        # En pahalƒ± √ºr√ºn
        expensive = df.nlargest(1, 'TL').iloc[0]
        insights.append(f"üíé **En Pahalƒ±:** {expensive['√úr√ºn T√ºrk√ße Adƒ±'][:50]}... - **{expensive['TL']:.0f}‚Ç∫** ({expensive['Marka']})")
        
        # Fiyat aralƒ±ƒüƒ± analizi
        price_range = df['TL'].max() - df['TL'].min()
        avg_price = df['TL'].mean()
        variance_pct = (price_range / avg_price) * 100 if avg_price > 0 else 0
        
        if variance_pct > 80:
            insights.append(f"üìä **Fiyat Varyasyonu √áok Y√ºksek:** %{variance_pct:.0f} - Dikkatli se√ßim yapƒ±n!")
        elif variance_pct > 50:
            insights.append(f"üìä **Orta Seviye Fiyat Farkƒ±:** %{variance_pct:.0f}")
        else:
            insights.append(f"üìä **Fiyatlar Tutarlƒ±:** %{variance_pct:.0f} varyasyon")
        
        # Marka bazlƒ± analiz (eƒüer birden fazla marka varsa)
        if df['Marka'].nunique() > 1:
            brand_avg = df.groupby('Marka')['TL'].mean().sort_values()
            cheapest_brand = brand_avg.index[0]
            expensive_brand = brand_avg.index[-1]
            
            insights.append(f"üèÜ **En Ekonomik Marka:** {cheapest_brand} (Ort: {brand_avg.iloc[0]:.0f}‚Ç∫)")
            insights.append(f"üí∏ **En Pahalƒ± Marka:** {expensive_brand} (Ort: {brand_avg.iloc[-1]:.0f}‚Ç∫)")
        
        # √úlke bazlƒ± √∂neri (eƒüer birden fazla √ºlke varsa)
        if df['√úlke'].nunique() > 1:
            country_avg = df.groupby('√úlke')['TL'].mean().sort_values()
            best_country = country_avg.index[0]
            insights.append(f"üåç **En Avantajlƒ± Pazar:** {best_country} (Ort: {country_avg.iloc[0]:.0f}‚Ç∫)")
        
    except Exception as e:
        logger.error(f"Insight generation error: {e}")
    
    return insights

# --- SIDEBAR ---
with st.sidebar:
    st.markdown('<h2 style="color:#4da6ff; margin-bottom:0;">LCW HOME</h2>', unsafe_allow_html=True)
    st.markdown('<p style="color:#8b949e; font-size:12px;">COMPETITOR PRICE TRACKER v2.0</p>', unsafe_allow_html=True)
    
    PERPLEXITY_KEY = os.environ.get("PERPLEXITY_API_KEY") or st.text_input("üîë Perplexity API Key", type="password")
    
    if not PERPLEXITY_KEY: 
        st.warning("‚ö†Ô∏è API Key Gerekli")
        st.stop()
    
    st.markdown("---")
    
    # Geli≈ümi≈ü filtreler
    st.header("üîé Arama Filtreleri")
    
    search_mode = st.radio("Mod Se√ß", ["Tek √úlke/Marka", "√áoklu Kar≈üƒ±la≈ütƒ±rma"])
    
    if search_mode == "Tek √úlke/Marka":
        available_countries = list(URL_DB.keys())
        sel_country = st.selectbox("√úlke", available_countries)
        sel_brands = [st.selectbox("Marka", BRANDS)]
    else:
        available_countries = list(URL_DB.keys())
        sel_country = st.selectbox("√úlke", available_countries)
        sel_brands = st.multiselect("Markalar (max 4)", BRANDS, default=["Pepco", "Zara Home"], max_selections=4)
        
        if not sel_brands:
            st.warning("En az 1 marka se√ß")
            sel_brands = ["Pepco"]
    
    q_tr = st.text_input("√úr√ºn (T√ºrk√ße)", "Y√ºz Havlusu")
    
    st.markdown("---")
    
    # Geli≈ümi≈ü ayarlar
    with st.expander("‚öôÔ∏è Geli≈ümi≈ü Ayarlar"):
        show_raw_data = st.checkbox("Ham API yanƒ±tlarƒ±nƒ± g√∂ster", value=False)
        min_price_filter = st.number_input("Min Fiyat (TL)", min_value=0, value=0)
        max_price_filter = st.number_input("Max Fiyat (TL)", min_value=0, value=10000)
    
    btn_start = st.button("üöÄ Fƒ∞YATLARI √áEK", type="primary")

# --- KURLAR ---
rates = get_rates()
conf = COUNTRIES_META.get(sel_country, {"curr": "USD", "lang": "en"})
curr = conf["curr"]

if rates:
    with st.sidebar:
        st.markdown("### üí± G√ºncel Kurlar")
        c1, c2 = st.columns(2)
        c1.metric("USD", f"{rates.get('USD',0):.2f}‚Ç∫")
        c2.metric(curr, f"{rates.get(curr,0):.2f}‚Ç∫")

# --- ANA ƒ∞≈ûLEM ---
if btn_start:
    if not rates: 
        st.error("‚ùå Kur verisi alƒ±namadƒ±. L√ºtfen internet baƒülantƒ±nƒ±zƒ± kontrol edin.")
        st.stop()
    
    all_results = []
    
    for sel_brand in sel_brands:
        target_url = URL_DB.get(sel_country, {}).get(sel_brand)
        
        if not target_url:
            st.warning(f"‚ö†Ô∏è {sel_brand} markasƒ±nƒ±n {sel_country} i√ßin maƒüazasƒ± yok - atlanƒ±yor")
            continue
        
        st.info(f"üéØ {sel_brand} taranƒ±yor: {target_url}")
        
        q_local = translate_logic(q_tr, "to_local", conf["lang"])
        q_english = translate_logic(q_tr, "to_english")
        
        # Cache kontrol√º
        cache_key = get_cache_key(sel_brand, q_tr, sel_country, curr)
        
        with st.spinner(f"üßø {sel_brand} maƒüazasƒ± taranƒ±yor... (Min 15 √ºr√ºn hedefleniyor)"):
            data = search_sonar_cached(sel_brand, q_local, q_english, sel_country, curr, target_url, cache_key)
        
        if show_raw_data and data:
            with st.expander(f"üîç {sel_brand} - Raw API Response"):
                st.json(data)
        
        if data and "products" in data and len(data["products"]) > 0:
            rows = []
            prices_tl = []
            usd_rate = rates.get("USD", 1)
            loc_rate = rates.get(curr, 1)
            
            pbar = st.progress(0, text=f"{sel_brand} √ºr√ºnleri i≈üleniyor...")
            tot = len(data["products"])
            
            valid_count = 0
            match_qualities = []
            
            for i, p in enumerate(data["products"]):
                loc_name = p.get("name", "Bilinmiyor")
                
                # Geli≈ütirilmi≈ü doƒürulama
                is_valid, eng_name_check, match_quality = validate_relevance_improved(loc_name, q_english)
                
                if is_valid:
                    p_raw = clean_price(p.get("price", 0), curr)
                    
                    if p_raw > 0:
                        p_tl = p_raw * loc_rate
                        p_usd = p_tl / usd_rate
                        
                        # Fiyat filtreleme
                        if min_price_filter <= p_tl <= max_price_filter or (min_price_filter == 0 and max_price_filter == 10000):
                            prices_tl.append(p_tl)
                            
                            tr_name = translate_logic(loc_name, "to_turkish")
                            
                            rows.append({
                                "Marka": sel_brand,
                                "√úlke": sel_country,
                                "√úr√ºn Yerel Adƒ±": loc_name,
                                "√úr√ºn T√ºrk√ße Adƒ±": tr_name,
                                "Yerel Fiyat": p_raw,
                                "USD": p_usd,
                                "TL": p_tl,
                                "Match Quality": match_quality,
                                "Link": p.get("url", "")
                            })
                            match_qualities.append(match_quality)
                            valid_count += 1
                
                pbar.progress((i + 1) / tot, text=f"{sel_brand}: {valid_count} ge√ßerli √ºr√ºn bulundu")
            
            pbar.empty()
            
            if rows:
                st.success(f"‚úÖ {sel_brand}: {valid_count} √ºr√ºn ba≈üarƒ±yla eklendi")
                all_results.extend(rows)
            else:
                st.error(f"‚ö†Ô∏è {sel_brand}: √úr√ºnler filtreye takƒ±ldƒ±. Aranan: '{q_english}'")
        
        else:
            st.error(f"‚ùå {sel_brand}: Sonu√ß bulunamadƒ±")
    
    # T√ºm sonu√ßlarƒ± birle≈ütir
    if all_results:
        df = pd.DataFrame(all_results)
        cols = ["Marka", "√úlke", "√úr√ºn Yerel Adƒ±", "√úr√ºn T√ºrk√ße Adƒ±", "Yerel Fiyat", "USD", "TL", "Match Quality", "Link"]
        df = df[cols]
        
        st.session_state['search_results'] = {
            "df": df,
            "search_time": datetime.now(),
            "query": q_tr,
            "country": sel_country,
            "brands": sel_brands
        }
    else:
        st.error("‚ùå Hi√ßbir markadan sonu√ß alƒ±namadƒ±")
        st.session_state['search_results'] = None

# --- RENDER RESULTS ---
if st.session_state['search_results'] is not None:
    res = st.session_state['search_results']
    df = res["df"]
    
    cnt = len(df)
    
    if cnt > 0:
        # Metrikler
        prices_tl = df['TL'].tolist()
        avg = df['TL'].mean()
        mn = df['TL'].min()
        mx = df['TL'].max()
        usd_rate = rates.get("USD", 1)
        loc_rate = rates.get(curr, 1)
        
        def fmt(val): 
            return f"{val:,.0f}‚Ç∫\n(${val/usd_rate:,.1f})\n({val/loc_rate:,.1f} {curr})"

        k1, k2, k3, k4 = st.columns(4)
        k1.metric("Bulunan √úr√ºn", f"{cnt} Adet")
        k2.metric("Ortalama", "Ort.", delta_color="off")
        k2.markdown(f"<div style='text-align:center;color:white;font-weight:bold;margin-top:-20px;white-space:pre-wrap;'>{fmt(avg)}</div>", unsafe_allow_html=True)
        k3.metric("En D√º≈ü√ºk", "Min", delta_color="off")
        k3.markdown(f"<div style='text-align:center;color:white;font-weight:bold;margin-top:-20px;white-space:pre-wrap;'>{fmt(mn)}</div>", unsafe_allow_html=True)
        k4.metric("En Y√ºksek", "Max", delta_color="off")
        k4.markdown(f"<div style='text-align:center;color:white;font-weight:bold;margin-top:-20px;white-space:pre-wrap;'>{fmt(mx)}</div>", unsafe_allow_html=True)
        
        st.markdown("---")
        
        # Insights
        insights = generate_insights(df)
        if insights:
            st.markdown("### üí° Analiz √ñnerileri")
            for insight in insights:
                st.markdown(f"<div class='insight-box'>{insight}</div>", unsafe_allow_html=True)
        
        st.markdown("---")
        
        # G√∂rselle≈ütirmeler
        if len(sel_brands) > 1 or df['Marka'].nunique() > 1:
            st.markdown("### üìä Fiyat Kar≈üƒ±la≈ütƒ±rmalarƒ±")
            
            col1, col2 = st.columns(2)
            
            with col1:
                # Marka bazlƒ± box plot
                fig_box = px.box(df, x="Marka", y="TL", color="Marka",
                               title="Marka Bazlƒ± Fiyat Daƒüƒ±lƒ±mƒ±",
                               labels={"TL": "Fiyat (‚Ç∫)", "Marka": ""},
                               template="plotly_dark")
                fig_box.update_layout(showlegend=False, height=400)
                st.plotly_chart(fig_box, use_container_width=True)
            
            with col2:
                # Marka bazlƒ± ortalama fiyat
                brand_avg = df.groupby('Marka')['TL'].mean().sort_values()
                fig_bar = px.bar(brand_avg, orientation='h',
                               title="Marka Ortalama Fiyatlarƒ±",
                               labels={"value": "Ortalama Fiyat (‚Ç∫)", "Marka": ""},
                               template="plotly_dark")
                fig_bar.update_layout(showlegend=False, height=400)
                st.plotly_chart(fig_bar, use_container_width=True)
        
        # Fiyat daƒüƒ±lƒ±mƒ± histogram
        fig_hist = px.histogram(df, x="TL", nbins=20, 
                               title="Fiyat Daƒüƒ±lƒ±mƒ±",
                               labels={"TL": "Fiyat (‚Ç∫)", "count": "√úr√ºn Sayƒ±sƒ±"},
                               template="plotly_dark")
        fig_hist.update_layout(height=300)
        st.plotly_chart(fig_hist, use_container_width=True)
        
        st.markdown("---")
        
        # Veri tablosu
        st.markdown("### üìã Detaylƒ± Sonu√ßlar")
        
        st.dataframe(
            df,
            column_config={
                "Link": st.column_config.LinkColumn("Link", display_text="üîó Git"),
                "Yerel Fiyat": st.column_config.NumberColumn(f"Fiyat ({curr})", format="%.2f"),
                "USD": st.column_config.NumberColumn("USD ($)", format="$%.2f"),
                "TL": st.column_config.NumberColumn("TL (‚Ç∫)", format="%.2f ‚Ç∫"),
                "Match Quality": st.column_config.TextColumn("E≈üle≈üme Kalitesi")
            },
            use_container_width=True,
            hide_index=True,
            height=500
        )
        
        # Export se√ßenekleri
        st.markdown("### üíæ ƒ∞ndir")
        
        col_exp1, col_exp2 = st.columns(2)
        
        with col_exp1:
            csv = df.to_csv(index=False).encode('utf-8-sig')
            st.download_button(
                "üì• CSV ƒ∞ndir",
                csv,
                f"lcw_analiz_{res['country']}_{datetime.now().strftime('%Y%m%d_%H%M')}.csv",
                "text/csv",
                use_container_width=True
            )
        
        with col_exp2:
            # Excel export (openpyxl ile)
            try:
                from io import BytesIO
                output = BytesIO()
                
                with pd.ExcelWriter(output, engine='xlsxwriter') as writer:
                    df.to_excel(writer, sheet_name='Fiyatlar', index=False)
                    
                    workbook = writer.book
                    worksheet = writer.sheets['Fiyatlar']
                    
                    # Format ayarlarƒ±
                    header_format = workbook.add_format({
                        'bold': True,
                        'bg_color': '#4da6ff',
                        'font_color': 'white',
                        'border': 1
                    })
                    
                    for col_num, value in enumerate(df.columns.values):
                        worksheet.write(0, col_num, value, header_format)
                        worksheet.set_column(col_num, col_num, 20)
                
                excel_data = output.getvalue()
                
                st.download_button(
                    "üìä Excel ƒ∞ndir",
                    excel_data,
                    f"lcw_analiz_{res['country']}_{datetime.now().strftime('%Y%m%d_%H%M')}.xlsx",
                    "application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
                    use_container_width=True
                )
            except ImportError:
                st.warning("Excel export i√ßin xlsxwriter y√ºkle: pip install xlsxwriter")

# --- FOOTER ---
st.markdown("---")
st.markdown(
    "<div style='text-align:center; color:#8b949e; font-size:12px;'>"
    f"LCW Global Intelligence v2.0 | Son Arama: {res.get('search_time', 'N/A') if st.session_state['search_results'] else 'Hen√ºz arama yapƒ±lmadƒ±'}"
    "</div>",
    unsafe_allow_html=True
)
